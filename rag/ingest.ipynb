{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c6041",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# RAG INGESTION NOTEBOOK\n",
    "# ===============================\n",
    "\n",
    "!pip install -q langchain langchain-community faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7e9fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c3611",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_json(data, prefix=\"\", source=\"\"):\n",
    "    docs = []\n",
    "    if isinstance(data, dict):\n",
    "        for k, v in data.items():\n",
    "            new_prefix = f\"{prefix}.{k}\" if prefix else k\n",
    "            docs.extend(flatten_json(v, new_prefix, source))\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            docs.extend(flatten_json(item, prefix, source))\n",
    "    else:\n",
    "        text = str(data).strip()\n",
    "        if text:\n",
    "            docs.append(\n",
    "                Document(\n",
    "                    page_content=f\"{prefix}: {text}\",\n",
    "                    metadata={\"source\": source}\n",
    "                )\n",
    "            )\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c6da82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/content/drive/MyDrive/new_rag\"\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file in os.listdir(DATA_DIR):\n",
    "    if not file.endswith(\".json\"):\n",
    "        continue\n",
    "    with open(os.path.join(DATA_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    documents.extend(flatten_json(data, source=file))\n",
    "\n",
    "print(\"Raw documents:\", len(documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aab06b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(\"Final chunks:\", len(chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384d80a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DYNAMIC_URLS = {\n",
    "    \"Admission deadlines\": [\n",
    "        \"https://ewubd.edu/undergraduate-dates-deadline\",\n",
    "        \"https://ewubd.edu/graduate-dates-deadline\"\n",
    "    ],\n",
    "    \"Events\": [\"https://ewubd.edu/events\"],\n",
    "    \"Faculty\": [\n",
    "        \"https://fse.ewubd.edu/computer-science-engineering/faculty-members\",\n",
    "        \"https://fse.ewubd.edu/electrical-electronic-engineering/faculty-members\",\n",
    "        \"https://fse.ewubd.edu/electronics-communications-engineering/faculty-members\",\n",
    "        \"https://fse.ewubd.edu/genetic-engineering-biotechnology/faculty-members\",\n",
    "        \"https://fse.ewubd.edu/pharmacy-department/faculty-members\",\n",
    "        \"https://fse.ewubd.edu/civil-engineering/faculty-members\",\n",
    "        \"https://fse.ewubd.edu/mathematical-physical-science/faculty-members\",\n",
    "        \"https://fbe.ewubd.edu/business-administration/faculty-members\",\n",
    "        \"https://fbe.ewubd.edu/economics-department/faculty-members\",\n",
    "        \"https://flass.ewubd.edu/english-department/faculty-members\",\n",
    "        \"https://flass.ewubd.edu/law-department/faculty-members\",\n",
    "        \"https://flass.ewubd.edu/social-relations-department/faculty-members\",\n",
    "        \"https://flass.ewubd.edu/information-studies-library-management/faculty-members\",\n",
    "        \"https://flass.ewubd.edu/sociology-department/faculty-members\"\n",
    "    ],\n",
    "    \"Grading\": [\"https://www.ewubd.edu/grades-rules-and-regulations\"],\n",
    "    \"Tuition fees\": [\"https://ewubd.edu/undergraduate-tuition-fees\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ff64c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def scrape_dynamic_docs(urls_dict):\n",
    "    docs = []\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    print(\"üîç Scraping live EWU website data...\")\n",
    "\n",
    "    for category, urls in urls_dict.items():\n",
    "        for url in urls:\n",
    "            try:\n",
    "                r = requests.get(url, headers=headers, timeout=15)\n",
    "                r.raise_for_status()\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "                for script in soup([\"script\", \"style\"]):\n",
    "                    script.decompose()\n",
    "\n",
    "                text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                docs.append(Document(\n",
    "                    page_content=f\"LATEST {category.upper()} INFO from official site ({url}):\\n{text}\",\n",
    "                    metadata={\"source\": url, \"category\": category}\n",
    "                ))\n",
    "                print(f\"‚úÖ Scraped: {url}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Failed to scrape {url}: {e}\")\n",
    "\n",
    "    print(f\"\\nüåê Total dynamic pages scraped: {len(docs)}\")\n",
    "    return docs\n",
    "\n",
    "# Now scrape and combine\n",
    "dynamic_docs = scrape_dynamic_docs(DYNAMIC_URLS)\n",
    "chunked_dynamic_docs = splitter.split_documents(dynamic_docs)  # reuse same splitter\n",
    "all_docs = chunks + chunked_dynamic_docs\n",
    "print(f\"üìö Total documents (JSON + live): {len(all_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f692b7be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(all_docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b97c5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = \"/content/vectorstore\"\n",
    "vectorstore.save_local(SAVE_PATH)\n",
    "print(\"‚úÖ Vectorstore saved at:\", SAVE_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
